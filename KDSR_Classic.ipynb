{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FR-mkOWimK0",
        "outputId": "81fde766-61aa-45b5-c272-0ff52ace2a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/KDSR-classic')"
      ],
      "metadata": {
        "id": "BNti4Qx6jFsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/KDSR-classic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZ_qOuPCZjE",
        "outputId": "58d52ee2-2f4f-4cd4-8278-9d3d7b26ac1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTzJAhPNjFuS",
        "outputId": "b10ae08e-8bfc-4288-d995-bc3fd357ad6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options_content = \"\"\"\\\n",
        "--dir_data='/content/gdrive/MyDrive/KDSR-classic/datasets'\n",
        "--model='blindsr'\n",
        "--scale='4'\n",
        "--blur_type='iso_gaussian'\n",
        "--noise=0\n",
        "--sig_min=0.2\n",
        "--sig_max=4.0\n",
        "--sig=3.6\n",
        "--n_GPUs=1\n",
        "--epochs_encoder=0\n",
        "--epochs_sr=1\n",
        "--data_test=Set14\n",
        "--st_save_epoch=1\n",
        "--data_train=DF2K\n",
        "--save='KDSRsMx4_iso_stage3'\n",
        "--patch_size=64\n",
        "--batch_size=64\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/gdrive/MyDrive/KDSR-classic/options.txt', 'w') as f:\n",
        "    f.write(options_content)\n"
      ],
      "metadata": {
        "id": "7031ztjBkALs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat options.txt | xargs python3 main_iso_stage3.py"
      ],
      "metadata": {
        "id": "2N02eNaQbztJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12de612b-e20c-40b2-c6e2-25addf4cb5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF2K\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/HR\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/LR_bicubic\n",
            "Making model...\n",
            "5822747\n",
            "Preparing loss function:\n",
            "1.000 * L1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "[Epoch 1]\tLearning rate: 1.00e-4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [0001][12800/63954]\tLoss [SR loss:0.040]\tTime [284.5s]\n",
            "Epoch: [0001][25600/63954]\tLoss [SR loss:0.037]\tTime [282.7s]\n",
            "Epoch: [0001][38400/63954]\tLoss [SR loss:0.037]\tTime [282.6s]\n",
            "Epoch: [0001][51200/63954]\tLoss [SR loss:0.032]\tTime [282.8s]\n",
            "Epoch: [0001][64000/63954]\tLoss [SR loss:0.029]\tTime [281.5s]\n",
            "\n",
            "Evaluation:\n",
            "[Epoch 0---['Set14'] x4]\tPSNR: 27.586 SSIM: 0.7617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options_content1 = \"\"\"\\\n",
        "--dir_data='/content/gdrive/MyDrive/KDSR-classic/datasets'\n",
        "               --model='blindsr'\n",
        "               --scale='4'\n",
        "               --blur_type='iso_gaussian'\n",
        "               --noise=0\n",
        "               --sig_min=0.2\n",
        "               --sig_max=4.0\n",
        "               --sig=3.6\n",
        "               --n_GPUs=1\n",
        "               --epochs_encoder 0\n",
        "               --epochs_sr 1\n",
        "               --lr_decay_sr 150\n",
        "               --data_test Set14\n",
        "               --st_save_epoch 0\n",
        "               --data_train DF2K\n",
        "               --save 'KDSRsMx4_iso_stage4'\n",
        "               --pre_train_TA=\"/content/gdrive/MyDrive/KDSR-classic/experiment/KDSRsMx4_iso_stage3_x4_bicubic_iso/model/model_TA_last.pt\"\n",
        "               --pre_train_ST=\"/content/gdrive/MyDrive/KDSR-classic/experiment/KDSRsMx4_iso_stage3_x4_bicubic_iso/model/model_TA_last.pt\"\n",
        "               --lr_encoder 2e-4\n",
        "               --patch_size 64\n",
        "               --batch_size 64\n",
        "               --resume 0\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/gdrive/MyDrive/KDSR-classic/options1.txt', 'w') as f:\n",
        "    f.write(options_content1)"
      ],
      "metadata": {
        "id": "Szy5k0GDHovC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat options1.txt | xargs python3 main_iso_stage4.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKhN5kWuUYs8",
        "outputId": "41e6d3d7-10ad-40d4-bdb3-251d25681ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF2K\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/HR\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/LR_bicubic\n",
            "Making model...\n",
            "Making model...\n",
            "Preparing loss function:\n",
            "1.000 * L1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "[Epoch 1]\tLearning rate: 1.00e-4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [0001][12800/63954]\tLoss [SR loss:0.038, distill_dis loss:0.258, distill_abs loss:0.086]\tTime [305.8s]\n",
            "Epoch: [0001][25600/63954]\tLoss [SR loss:0.037, distill_dis loss:0.129, distill_abs loss:0.061]\tTime [306.9s]\n",
            "Epoch: [0001][38400/63954]\tLoss [SR loss:0.036, distill_dis loss:0.086, distill_abs loss:0.050]\tTime [307.0s]\n",
            "Epoch: [0001][51200/63954]\tLoss [SR loss:0.035, distill_dis loss:0.065, distill_abs loss:0.042]\tTime [306.8s]\n",
            "Epoch: [0001][64000/63954]\tLoss [SR loss:0.035, distill_dis loss:0.052, distill_abs loss:0.037]\tTime [305.9s]\n",
            "\n",
            "Evaluation:\n",
            "[Epoch 0---['Set14'] x4]\tPSNR: 27.822 SSIM: 0.7663 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GM8Y-asBn6dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options_content2 = \"\"\"\\\n",
        "--dir_data='/content/gdrive/MyDrive/KDSR-classic/datasets'\n",
        "--model='blindsr'\n",
        "--scale='4'\n",
        "--blur_type='aniso_gaussian'\n",
        "--noise=25.0\n",
        "--lambda_min=0.2\n",
        "--lambda_max=4.0\n",
        "--lambda_1 4.0\n",
        "--lambda_2 1.5\n",
        "--theta 120\n",
        "--n_GPUs=1\n",
        "--epochs_encoder 0\n",
        "--epochs_sr 1\n",
        "--data_test Set14\n",
        "--st_save_epoch 1\n",
        "--data_train DF2K\n",
        "--save 'KDSRsMx4_anisonoise_stage3'\n",
        "--patch_size 8\n",
        "--batch_size 4\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/gdrive/MyDrive/KDSR-classic/options2.txt', 'w') as f:\n",
        "    f.write(options_content2)\n"
      ],
      "metadata": {
        "id": "B9oz92_7UmH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF='max_split_size_mb=256'\n"
      ],
      "metadata": {
        "id": "pTkIE2yiqsw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat options2.txt | xargs python3 main_anisonoise_stage3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SpP9vvnhknE",
        "outputId": "d3c8ddb3-b20c-4266-877e-c8735c6b40d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF2K\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/HR\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/LR_bicubic\n",
            "Making model...\n",
            "5822747\n",
            "Preparing loss function:\n",
            "1.000 * L1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "[Epoch 1]\tLearning rate: 1.00e-4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [0001][0800/3960]\tLoss [SR loss:0.088]\tTime [26.0s]\n",
            "Epoch: [0001][1600/3960]\tLoss [SR loss:0.041]\tTime [22.1s]\n",
            "Epoch: [0001][2400/3960]\tLoss [SR loss:0.081]\tTime [21.9s]\n",
            "Epoch: [0001][3200/3960]\tLoss [SR loss:0.074]\tTime [21.4s]\n",
            "\n",
            "Evaluation:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/KDSR-classic/main_anisonoise_stage3.py\", line 27, in <module>\n",
            "    t.test()\n",
            "  File \"/content/gdrive/MyDrive/KDSR-classic/trainer_anisonoise_stage3.py\", line 154, in test\n",
            "    sr = self.model_TA(lr_blur, torch.cat([lr_blur, hr2], dim=1))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/KDSR-classic/model_TA/__init__.py\", line 49, in forward\n",
            "    return self.model(x, deg_repre)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/KDSR-classic/model_TA/blindsr.py\", line 215, in forward\n",
            "    sr = self.G(x, deg_repre)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/KDSR-classic/model_TA/blindsr.py\", line 133, in forward\n",
            "    x = self.tail(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 215, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 215, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pixelshuffle.py\", line 54, in forward\n",
            "    return F.pixel_shuffle(input, self.upscale_factor)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 766.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 7.06 MiB is free. Process 32945 has 14.74 GiB memory in use. Of the allocated memory 14.00 GiB is allocated by PyTorch, and 567.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gputil\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQdOtTzYhvXE",
        "outputId": "56208c3b-ac73-4b20-c330-cef14f60a5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=9938e2c1d06e41180d932456a83c6d6f9adc6301ee62e8b07437e8c6cefca6f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import GPUtil\n",
        "\n",
        "# Get the list of available GPUs\n",
        "gpus = GPUtil.getGPUs()\n",
        "\n",
        "# Print GPU information\n",
        "for gpu in gpus:\n",
        "    print(f\"GPU ID: {gpu.id}, Name: {gpu.name}, Free Memory: {gpu.memoryFree} MB, Used Memory: {gpu.memoryUsed} MB, Total Memory: {gpu.memoryTotal} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY0ML-Zmhb4h",
        "outputId": "2ab06a4c-f2fb-474e-acef-1b37f22b6125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU ID: 0, Name: Tesla T4, Free Memory: 15101.0 MB, Used Memory: 0.0 MB, Total Memory: 15360.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import GPUtil\n",
        "\n",
        "# Get the list of available GPUs\n",
        "gpus = GPUtil.getGPUs()\n",
        "\n",
        "# Print GPU information\n",
        "for gpu in gpus:\n",
        "    print(f\"GPU ID: {gpu.id}, Name: {gpu.name}, Free Memory: {gpu.memoryFree} MB, Used Memory: {gpu.memoryUsed} MB, Total Memory: {gpu.memoryTotal} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFzXcRl6hfW3",
        "outputId": "fcac7d21-cc15-4bbf-b12f-6d5422b76862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU ID: 0, Name: Tesla T4, Free Memory: 15101.0 MB, Used Memory: 0.0 MB, Total Memory: 15360.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options_content3 = \"\"\"\\\n",
        "--dir_data='/content/gdrive/MyDrive/KDSR-classic/datasets'\n",
        "--model='blindsr'\n",
        "--scale='4'\n",
        "--blur_type='iso_gaussian'\n",
        "--noise=0\n",
        "--sig_min=0.5\n",
        "--sig_max=3.0\n",
        "--sig=2.0\n",
        "--n_GPUs=1\n",
        "--epochs_encoder=0\n",
        "--epochs_sr=1\n",
        "--data_test=Set14\n",
        "--st_save_epoch=1\n",
        "--data_train=DF2K\n",
        "--save='KDSRsMx4_iso_stage3'\n",
        "--patch_size=64\n",
        "--batch_size=32\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/gdrive/MyDrive/KDSR-classic/options3.txt', 'w') as f:\n",
        "    f.write(options_content3)"
      ],
      "metadata": {
        "id": "8u6rFtvNIqPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat options3.txt | xargs python3 main_iso_stage3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mptMbuUdIqSU",
        "outputId": "9477b6b1-63d1-4517-b870-59bb9709ea77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF2K\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/HR\n",
            "/content/gdrive/MyDrive/KDSR-classic/datasets/benchmark/Set14/LR_bicubic\n",
            "Making model...\n",
            "5822747\n",
            "Preparing loss function:\n",
            "1.000 * L1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "[Epoch 1]\tLearning rate: 1.00e-4\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [0001][6400/31977]\tLoss [SR loss:0.040]\tTime [134.9s]\n",
            "Epoch: [0001][12800/31977]\tLoss [SR loss:0.037]\tTime [132.9s]\n",
            "Epoch: [0001][19200/31977]\tLoss [SR loss:0.032]\tTime [133.0s]\n",
            "Epoch: [0001][25600/31977]\tLoss [SR loss:0.038]\tTime [132.9s]\n",
            "Epoch: [0001][32000/31977]\tLoss [SR loss:0.039]\tTime [132.5s]\n",
            "\n",
            "Evaluation:\n",
            "[Epoch 0---['Set14'] x4]\tPSNR: 27.407 SSIM: 0.7563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMgd0VS-jdgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}