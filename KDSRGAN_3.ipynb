{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbqJI4nMQ64h",
        "outputId": "1803dd17-a713-4044-c7a0-bd80b3cf91c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/KDSR-GAN')"
      ],
      "metadata": {
        "id": "ctQ3pPueRBns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/KDSR-GAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JwRAfN8RBpb",
        "outputId": "40f4fe35-c866-4b9c-991a-2dfae6f0f5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr\n",
        "!pip install pandas\n",
        "!pip install -r requirements.txt\n",
        "!sudo python3 setup.py develop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRYRQtTwRBtO",
        "outputId": "8cd61cff-7e23-49b7-9596-4b3a530a7df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting basicsr\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from basicsr)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.18.3)\n",
            "Collecting lmdb (from basicsr)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.31.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.11.4)\n",
            "Collecting tb-nightly (from basicsr)\n",
            "  Downloading tb_nightly-2.16.0a20240203-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.66.1)\n",
            "Collecting yapf (from basicsr)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2023.11.17)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2024.1.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (23.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.60.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (0.7.2)\n",
            "Collecting tf-keras-nightly (from tb-nightly->basicsr)\n",
            "  Downloading tf_keras_nightly-2.16.0.dev2024020310-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (7.0.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->basicsr) (1.3.0)\n",
            "Building wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214817 sha256=cea99fc4d5db6a2be8a9f070a5288bcd5ef828aaa5f4d4f11292c7afeb27ca33\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/83/99/2d8437cc652a01af27df5ff037a4075e95b52d67705c5f30ca\n",
            "Successfully built basicsr\n",
            "Installing collected packages: lmdb, addict, tf-keras-nightly, yapf, tb-nightly, basicsr\n",
            "Successfully installed addict-2.4.0 basicsr-1.4.2 lmdb-1.4.1 tb-nightly-2.16.0a20240203 tf-keras-nightly-2.16.0.dev2024020310 yapf-0.40.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: basicsr>=1.3.3.11 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.4.2)\n",
            "Collecting facexlib>=0.2.0.3 (from -r requirements.txt (line 2))\n",
            "  Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gfpgan>=0.2.1 (from -r requirements.txt (line 3))\n",
            "  Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (9.4.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (0.18.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.16.0a20240203)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.3.3.11->-r requirements.txt (line 1)) (0.40.2)\n",
            "Collecting filterpy (from facexlib>=0.2.0.3->-r requirements.txt (line 2))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.0.3->-r requirements.txt (line 2)) (0.58.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->-r requirements.txt (line 7)) (2.1.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2024.1.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (1.60.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: tf-keras-nightly in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.16.0.dev2024020310)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (7.0.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr>=1.3.3.11->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->-r requirements.txt (line 2)) (2.8.2)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=5893f653cfe43c8ea9b9aa67554f2bc0a3f60ad82fbafff2bc6e5a3daaabbb3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy, facexlib, gfpgan\n",
            "Successfully installed facexlib-0.3.0 filterpy-1.4.5 gfpgan-1.3.8\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "writing realesrgan.egg-info/PKG-INFO\n",
            "writing dependency_links to realesrgan.egg-info/dependency_links.txt\n",
            "writing requirements to realesrgan.egg-info/requires.txt\n",
            "writing top-level names to realesrgan.egg-info/top_level.txt\n",
            "reading manifest file 'realesrgan.egg-info/SOURCES.txt'\n",
            "writing manifest file 'realesrgan.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.10/dist-packages/realesrgan.egg-link (link to .)\n",
            "Adding realesrgan 0.2.5.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/gdrive/MyDrive/KDSR-GAN\n",
            "Processing dependencies for realesrgan==0.2.5.0\n",
            "Searching for tqdm==4.66.1\n",
            "Best match: tqdm 4.66.1\n",
            "Adding tqdm 4.66.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torchvision==0.16.0+cu121\n",
            "Best match: torchvision 0.16.0+cu121\n",
            "Adding torchvision 0.16.0+cu121 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torch==2.1.0+cu121\n",
            "Best match: torch 2.1.0+cu121\n",
            "Adding torch 2.1.0+cu121 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Pillow==9.4.0\n",
            "Best match: Pillow 9.4.0\n",
            "Adding Pillow 9.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for opencv-python==4.8.0.76\n",
            "Best match: opencv-python 4.8.0.76\n",
            "Adding opencv-python 4.8.0.76 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.23.5\n",
            "Best match: numpy 1.23.5\n",
            "Adding numpy 1.23.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for gfpgan==1.3.8\n",
            "Best match: gfpgan 1.3.8\n",
            "Adding gfpgan 1.3.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for facexlib==0.3.0\n",
            "Best match: facexlib 0.3.0\n",
            "Adding facexlib 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for basicsr==1.4.2\n",
            "Best match: basicsr 1.4.2\n",
            "Adding basicsr 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests==2.31.0\n",
            "Best match: requests 2.31.0\n",
            "Adding requests 2.31.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for triton==2.1.0\n",
            "Best match: triton 2.1.0\n",
            "Adding triton 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fsspec==2023.6.0\n",
            "Best match: fsspec 2023.6.0\n",
            "Adding fsspec 2023.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Jinja2==3.1.3\n",
            "Best match: Jinja2 3.1.3\n",
            "Adding Jinja2 3.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.2.1\n",
            "Best match: networkx 3.2.1\n",
            "Adding networkx 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.12\n",
            "Best match: sympy 1.12\n",
            "Adding sympy 1.12 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filelock==3.13.1\n",
            "Best match: filelock 3.13.1\n",
            "Adding filelock 3.13.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for yapf==0.40.2\n",
            "Best match: yapf 0.40.2\n",
            "Adding yapf 0.40.2 to easy-install.pth file\n",
            "Installing yapf script to /usr/local/bin\n",
            "Installing yapf-diff script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tb-nightly==2.16.0a20240203\n",
            "Best match: tb-nightly 2.16.0a20240203\n",
            "Adding tb-nightly 2.16.0a20240203 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scipy==1.11.4\n",
            "Best match: scipy 1.11.4\n",
            "Adding scipy 1.11.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for PyYAML==6.0.1\n",
            "Best match: PyYAML 6.0.1\n",
            "Adding PyYAML 6.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for lmdb==1.4.1\n",
            "Best match: lmdb 1.4.1\n",
            "Adding lmdb 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numba==0.58.1\n",
            "Best match: numba 0.58.1\n",
            "Adding numba 0.58.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filterpy==1.4.5\n",
            "Best match: filterpy 1.4.5\n",
            "Adding filterpy 1.4.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scikit-image==0.19.3\n",
            "Best match: scikit-image 0.19.3\n",
            "Adding scikit-image 0.19.3 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for future==0.18.3\n",
            "Best match: future 0.18.3\n",
            "Adding future 0.18.3 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for addict==2.4.0\n",
            "Best match: addict 2.4.0\n",
            "Adding addict 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for certifi==2023.11.17\n",
            "Best match: certifi 2023.11.17\n",
            "Adding certifi 2023.11.17 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for urllib3==2.0.7\n",
            "Best match: urllib3 2.0.7\n",
            "Adding urllib3 2.0.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for idna==3.6\n",
            "Best match: idna 3.6\n",
            "Adding idna 3.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for charset-normalizer==3.3.2\n",
            "Best match: charset-normalizer 3.3.2\n",
            "Adding charset-normalizer 3.3.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==2.1.4\n",
            "Best match: MarkupSafe 2.1.4\n",
            "Adding MarkupSafe 2.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tomli==2.0.1\n",
            "Best match: tomli 2.0.1\n",
            "Adding tomli 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for platformdirs==4.2.0\n",
            "Best match: platformdirs 4.2.0\n",
            "Adding platformdirs 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for importlib-metadata==7.0.1\n",
            "Best match: importlib-metadata 7.0.1\n",
            "Adding importlib-metadata 7.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for werkzeug==3.0.1\n",
            "Best match: werkzeug 3.0.1\n",
            "Adding werkzeug 3.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tf-keras-nightly==2.16.0.dev2024020310\n",
            "Best match: tf-keras-nightly 2.16.0.dev2024020310\n",
            "Adding tf-keras-nightly 2.16.0.dev2024020310 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tensorboard-data-server==0.7.2\n",
            "Best match: tensorboard-data-server 0.7.2\n",
            "Adding tensorboard-data-server 0.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for six==1.16.0\n",
            "Best match: six 1.16.0\n",
            "Adding six 1.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for setuptools==67.7.2\n",
            "Best match: setuptools 67.7.2\n",
            "Adding setuptools 67.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for protobuf==3.20.3\n",
            "Best match: protobuf 3.20.3\n",
            "Adding protobuf 3.20.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Markdown==3.5.2\n",
            "Best match: Markdown 3.5.2\n",
            "Adding Markdown 3.5.2 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for grpcio==1.60.0\n",
            "Best match: grpcio 1.60.0\n",
            "Adding grpcio 1.60.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for absl-py==1.4.0\n",
            "Best match: absl-py 1.4.0\n",
            "Adding absl-py 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for llvmlite==0.41.1\n",
            "Best match: llvmlite 0.41.1\n",
            "Adding llvmlite 0.41.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for matplotlib==3.7.1\n",
            "Best match: matplotlib 3.7.1\n",
            "Adding matplotlib 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for packaging==23.2\n",
            "Best match: packaging 23.2\n",
            "Adding packaging 23.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pywavelets==1.5.0\n",
            "Best match: pywavelets 1.5.0\n",
            "Adding pywavelets 1.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tifffile==2024.1.30\n",
            "Best match: tifffile 2024.1.30\n",
            "Adding tifffile 2024.1.30 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tiff2fsspec script to /usr/local/bin\n",
            "Installing tiffcomment script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for imageio==2.31.6\n",
            "Best match: imageio 2.31.6\n",
            "Adding imageio 2.31.6 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for zipp==3.17.0\n",
            "Best match: zipp 3.17.0\n",
            "Adding zipp 3.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyparsing==3.1.1\n",
            "Best match: pyparsing 3.1.1\n",
            "Adding pyparsing 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for kiwisolver==1.4.5\n",
            "Best match: kiwisolver 1.4.5\n",
            "Adding kiwisolver 1.4.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fonttools==4.47.2\n",
            "Best match: fonttools 4.47.2\n",
            "Adding fonttools 4.47.2 to easy-install.pth file\n",
            "Installing fonttools script to /usr/local/bin\n",
            "Installing pyftmerge script to /usr/local/bin\n",
            "Installing pyftsubset script to /usr/local/bin\n",
            "Installing ttx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cycler==0.12.1\n",
            "Best match: cycler 0.12.1\n",
            "Adding cycler 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for contourpy==1.2.0\n",
            "Best match: contourpy 1.2.0\n",
            "Adding contourpy 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for realesrgan==0.2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '1'"
      ],
      "metadata": {
        "id": "5f1stRYARIW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Directory path containing the images\n",
        "directory_path = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt'\n",
        "\n",
        "# Output directory where resized images will be saved\n",
        "output_directory = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized'\n",
        "\n",
        "# Target size for resizing\n",
        "target_size = (1020,678)  # Change this to your desired size\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# List all files in the directory\n",
        "image_files = [f for f in os.listdir(directory_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Iterate over the image files and resize\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(directory_path, image_file)\n",
        "\n",
        "    # Open the image with Pillow\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_img = img.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "    # Save the resized image to the output directory\n",
        "    output_path = os.path.join(output_directory, image_file)\n",
        "    resized_img.save(output_path)\n",
        "\n",
        "    print(f\"Resized {image_file} to {target_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEZJShCXSr2z",
        "outputId": "e4616994-3ef4-4537-c4d6-dabad5b76911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-739278074199>:27: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  resized_img = img.resize(target_size, Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized 000400.png to (1020, 678)\n",
            "Resized 000401.png to (1020, 678)\n",
            "Resized 000402.png to (1020, 678)\n",
            "Resized 000403.png to (1020, 678)\n",
            "Resized 000404.png to (1020, 678)\n",
            "Resized 000405.png to (1020, 678)\n",
            "Resized 000406.png to (1020, 678)\n",
            "Resized 000407.png to (1020, 678)\n",
            "Resized 000409.png to (1020, 678)\n",
            "Resized 000408.png to (1020, 678)\n",
            "Resized 000410.png to (1020, 678)\n",
            "Resized 000412.png to (1020, 678)\n",
            "Resized 000413.png to (1020, 678)\n",
            "Resized 000411.png to (1020, 678)\n",
            "Resized 000414.png to (1020, 678)\n",
            "Resized 000415.png to (1020, 678)\n",
            "Resized 000416.png to (1020, 678)\n",
            "Resized 000418.png to (1020, 678)\n",
            "Resized 000417.png to (1020, 678)\n",
            "Resized 000420.png to (1020, 678)\n",
            "Resized 000419.png to (1020, 678)\n",
            "Resized 000421.png to (1020, 678)\n",
            "Resized 000422.png to (1020, 678)\n",
            "Resized 000423.png to (1020, 678)\n",
            "Resized 000424.png to (1020, 678)\n",
            "Resized 000425.png to (1020, 678)\n",
            "Resized 000426.png to (1020, 678)\n",
            "Resized 000428.png to (1020, 678)\n",
            "Resized 000427.png to (1020, 678)\n",
            "Resized 000429.png to (1020, 678)\n",
            "Resized 000430.png to (1020, 678)\n",
            "Resized 000431.png to (1020, 678)\n",
            "Resized 000433.png to (1020, 678)\n",
            "Resized 000432.png to (1020, 678)\n",
            "Resized 000434.png to (1020, 678)\n",
            "Resized 000436.png to (1020, 678)\n",
            "Resized 000435.png to (1020, 678)\n",
            "Resized 000437.png to (1020, 678)\n",
            "Resized 000438.png to (1020, 678)\n",
            "Resized 000439.png to (1020, 678)\n",
            "Resized 000440.png to (1020, 678)\n",
            "Resized 000441.png to (1020, 678)\n",
            "Resized 000442.png to (1020, 678)\n",
            "Resized 000443.png to (1020, 678)\n",
            "Resized 000444.png to (1020, 678)\n",
            "Resized 000445.png to (1020, 678)\n",
            "Resized 000446.png to (1020, 678)\n",
            "Resized 000447.png to (1020, 678)\n",
            "Resized 000448.png to (1020, 678)\n",
            "Resized 000449.png to (1020, 678)\n",
            "Resized 000450.png to (1020, 678)\n",
            "Resized 000451.png to (1020, 678)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Directory path containing the images\n",
        "directory_path = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq'\n",
        "\n",
        "# Output directory where resized images will be saved\n",
        "output_directory = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized'\n",
        "\n",
        "# Target size for resizing\n",
        "target_size = (1020, 678)  # Change this to your desired size\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# List all files in the directory\n",
        "image_files = [f for f in os.listdir(directory_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Iterate over the image files and resize or copy\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(directory_path, image_file)\n",
        "\n",
        "    # Open the image with Pillow\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Check if the image needs resizing\n",
        "    if img.size != target_size:\n",
        "        # Resize the image\n",
        "        img = img.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "        # Save the resized image to the output directory\n",
        "        output_path = os.path.join(output_directory, image_file)\n",
        "        img.save(output_path)\n",
        "        print(f\"Resized {image_file} to {target_size}\")\n",
        "    else:\n",
        "        # Copy the original image to the output directory\n",
        "        output_path = os.path.join(output_directory, image_file)\n",
        "        img.save(output_path)\n",
        "        print(f\"Copied original {image_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxYq3dDFSr5u",
        "outputId": "8d9d89ad-b875-484e-9bf0-ea9742b1bf2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5d233fda156a>:29: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img = img.resize(target_size, Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized 000402.png to (1020, 678)\n",
            "Resized 000400.png to (1020, 678)\n",
            "Resized 000401.png to (1020, 678)\n",
            "Resized 000406.png to (1020, 678)\n",
            "Resized 000403.png to (1020, 678)\n",
            "Copied original 000410.png\n",
            "Resized 000404.png to (1020, 678)\n",
            "Copied original 000408.png\n",
            "Copied original 000409.png\n",
            "Resized 000405.png to (1020, 678)\n",
            "Copied original 000407.png\n",
            "Resized 000415.png to (1020, 678)\n",
            "Resized 000414.png to (1020, 678)\n",
            "Resized 000412.png to (1020, 678)\n",
            "Resized 000417.png to (1020, 678)\n",
            "Resized 000413.png to (1020, 678)\n",
            "Copied original 000411.png\n",
            "Resized 000416.png to (1020, 678)\n",
            "Resized 000419.png to (1020, 678)\n",
            "Resized 000418.png to (1020, 678)\n",
            "Resized 000420.png to (1020, 678)\n",
            "Resized 000422.png to (1020, 678)\n",
            "Resized 000423.png to (1020, 678)\n",
            "Copied original 000424.png\n",
            "Copied original 000421.png\n",
            "Resized 000426.png to (1020, 678)\n",
            "Copied original 000429.png\n",
            "Copied original 000428.png\n",
            "Copied original 000427.png\n",
            "Resized 000425.png to (1020, 678)\n",
            "Resized 000430.png to (1020, 678)\n",
            "Resized 000432.png to (1020, 678)\n",
            "Copied original 000431.png\n",
            "Copied original 000433.png\n",
            "Resized 000434.png to (1020, 678)\n",
            "Resized 000437.png to (1020, 678)\n",
            "Resized 000438.png to (1020, 678)\n",
            "Copied original 000436.png\n",
            "Copied original 000435.png\n",
            "Copied original 000439.png\n",
            "Resized 000440.png to (1020, 678)\n",
            "Resized 000442.png to (1020, 678)\n",
            "Resized 000441.png to (1020, 678)\n",
            "Copied original 000444.png\n",
            "Resized 000443.png to (1020, 678)\n",
            "Copied original 000445.png\n",
            "Resized 000446.png to (1020, 678)\n",
            "Resized 000448.png to (1020, 678)\n",
            "Resized 000447.png to (1020, 678)\n",
            "Resized 000449.png to (1020, 678)\n",
            "Copied original 000451.png\n",
            "Resized 000450.png to (1020, 678)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "def count_images(directory_path):\n",
        "    # Define the image file extensions you want to consider\n",
        "    image_extensions = ['png', 'jpg', 'jpeg']\n",
        "\n",
        "    # Create a glob pattern to match image files\n",
        "    pattern = f\"{directory_path}/*.*\"\n",
        "    image_files = [file for file in glob.glob(pattern) if file.lower().split('.')[-1] in image_extensions]\n",
        "\n",
        "    # Get the number of images\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    # Print the number of images\n",
        "    print(f\"Number of Images in {directory_path}: {num_images}\")\n",
        "\n",
        "# Directory path containing the resized ground truth images\n",
        "gt_resized_directory = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized'\n",
        "count_images(gt_resized_directory)\n",
        "\n",
        "# Directory path containing the resized low-quality images\n",
        "lq_resized_directory = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized'\n",
        "count_images(lq_resized_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPPUbM7wRq1Y",
        "outputId": "22aa6565-74eb-4381-bc18-b9277cd0a55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images in /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized: 52\n",
            "Number of Images in /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "directory_path = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized'\n",
        "\n",
        "# List all files in the directory\n",
        "image_files = [f for f in os.listdir(directory_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Iterate over the image files and print their sizes\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(directory_path, image_file)\n",
        "\n",
        "    # Open the image with Pillow\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Print the image size\n",
        "    print(f\"Image: {image_file}, Size: {img.size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORvg6a65p55x",
        "outputId": "96b9bed9-8f84-4325-e5e7-a85eae9454d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 000402.png, Size: (1020, 678)\n",
            "Image: 000400.png, Size: (1020, 678)\n",
            "Image: 000401.png, Size: (1020, 678)\n",
            "Image: 000406.png, Size: (1020, 678)\n",
            "Image: 000403.png, Size: (1020, 678)\n",
            "Image: 000410.png, Size: (1020, 678)\n",
            "Image: 000404.png, Size: (1020, 678)\n",
            "Image: 000408.png, Size: (1020, 678)\n",
            "Image: 000409.png, Size: (1020, 678)\n",
            "Image: 000405.png, Size: (1020, 678)\n",
            "Image: 000407.png, Size: (1020, 678)\n",
            "Image: 000415.png, Size: (1020, 678)\n",
            "Image: 000414.png, Size: (1020, 678)\n",
            "Image: 000412.png, Size: (1020, 678)\n",
            "Image: 000417.png, Size: (1020, 678)\n",
            "Image: 000413.png, Size: (1020, 678)\n",
            "Image: 000411.png, Size: (1020, 678)\n",
            "Image: 000416.png, Size: (1020, 678)\n",
            "Image: 000419.png, Size: (1020, 678)\n",
            "Image: 000418.png, Size: (1020, 678)\n",
            "Image: 000420.png, Size: (1020, 678)\n",
            "Image: 000422.png, Size: (1020, 678)\n",
            "Image: 000423.png, Size: (1020, 678)\n",
            "Image: 000424.png, Size: (1020, 678)\n",
            "Image: 000421.png, Size: (1020, 678)\n",
            "Image: 000426.png, Size: (1020, 678)\n",
            "Image: 000429.png, Size: (1020, 678)\n",
            "Image: 000428.png, Size: (1020, 678)\n",
            "Image: 000427.png, Size: (1020, 678)\n",
            "Image: 000425.png, Size: (1020, 678)\n",
            "Image: 000430.png, Size: (1020, 678)\n",
            "Image: 000432.png, Size: (1020, 678)\n",
            "Image: 000431.png, Size: (1020, 678)\n",
            "Image: 000433.png, Size: (1020, 678)\n",
            "Image: 000434.png, Size: (1020, 678)\n",
            "Image: 000437.png, Size: (1020, 678)\n",
            "Image: 000438.png, Size: (1020, 678)\n",
            "Image: 000436.png, Size: (1020, 678)\n",
            "Image: 000435.png, Size: (1020, 678)\n",
            "Image: 000439.png, Size: (1020, 678)\n",
            "Image: 000440.png, Size: (1020, 678)\n",
            "Image: 000442.png, Size: (1020, 678)\n",
            "Image: 000441.png, Size: (1020, 678)\n",
            "Image: 000444.png, Size: (1020, 678)\n",
            "Image: 000443.png, Size: (1020, 678)\n",
            "Image: 000445.png, Size: (1020, 678)\n",
            "Image: 000446.png, Size: (1020, 678)\n",
            "Image: 000448.png, Size: (1020, 678)\n",
            "Image: 000447.png, Size: (1020, 678)\n",
            "Image: 000449.png, Size: (1020, 678)\n",
            "Image: 000451.png, Size: (1020, 678)\n",
            "Image: 000450.png, Size: (1020, 678)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "directory_path = '/content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized'\n",
        "\n",
        "# List all files in the directory\n",
        "image_files = [f for f in os.listdir(directory_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Iterate over the image files and print their sizes\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(directory_path, image_file)\n",
        "\n",
        "    # Open the image with Pillow\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Print the image size\n",
        "    print(f\"Image: {image_file}, Size: {img.size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0nfgjy4p58v",
        "outputId": "8acd4fc3-73e6-4299-8a0b-b8363f7269fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 000400.png, Size: (1020, 678)\n",
            "Image: 000401.png, Size: (1020, 678)\n",
            "Image: 000402.png, Size: (1020, 678)\n",
            "Image: 000403.png, Size: (1020, 678)\n",
            "Image: 000404.png, Size: (1020, 678)\n",
            "Image: 000405.png, Size: (1020, 678)\n",
            "Image: 000406.png, Size: (1020, 678)\n",
            "Image: 000407.png, Size: (1020, 678)\n",
            "Image: 000409.png, Size: (1020, 678)\n",
            "Image: 000408.png, Size: (1020, 678)\n",
            "Image: 000410.png, Size: (1020, 678)\n",
            "Image: 000412.png, Size: (1020, 678)\n",
            "Image: 000413.png, Size: (1020, 678)\n",
            "Image: 000411.png, Size: (1020, 678)\n",
            "Image: 000414.png, Size: (1020, 678)\n",
            "Image: 000415.png, Size: (1020, 678)\n",
            "Image: 000416.png, Size: (1020, 678)\n",
            "Image: 000418.png, Size: (1020, 678)\n",
            "Image: 000417.png, Size: (1020, 678)\n",
            "Image: 000420.png, Size: (1020, 678)\n",
            "Image: 000419.png, Size: (1020, 678)\n",
            "Image: 000421.png, Size: (1020, 678)\n",
            "Image: 000422.png, Size: (1020, 678)\n",
            "Image: 000423.png, Size: (1020, 678)\n",
            "Image: 000424.png, Size: (1020, 678)\n",
            "Image: 000425.png, Size: (1020, 678)\n",
            "Image: 000426.png, Size: (1020, 678)\n",
            "Image: 000428.png, Size: (1020, 678)\n",
            "Image: 000427.png, Size: (1020, 678)\n",
            "Image: 000429.png, Size: (1020, 678)\n",
            "Image: 000430.png, Size: (1020, 678)\n",
            "Image: 000431.png, Size: (1020, 678)\n",
            "Image: 000433.png, Size: (1020, 678)\n",
            "Image: 000432.png, Size: (1020, 678)\n",
            "Image: 000434.png, Size: (1020, 678)\n",
            "Image: 000436.png, Size: (1020, 678)\n",
            "Image: 000435.png, Size: (1020, 678)\n",
            "Image: 000437.png, Size: (1020, 678)\n",
            "Image: 000438.png, Size: (1020, 678)\n",
            "Image: 000439.png, Size: (1020, 678)\n",
            "Image: 000440.png, Size: (1020, 678)\n",
            "Image: 000441.png, Size: (1020, 678)\n",
            "Image: 000442.png, Size: (1020, 678)\n",
            "Image: 000443.png, Size: (1020, 678)\n",
            "Image: 000444.png, Size: (1020, 678)\n",
            "Image: 000445.png, Size: (1020, 678)\n",
            "Image: 000446.png, Size: (1020, 678)\n",
            "Image: 000447.png, Size: (1020, 678)\n",
            "Image: 000448.png, Size: (1020, 678)\n",
            "Image: 000449.png, Size: (1020, 678)\n",
            "Image: 000450.png, Size: (1020, 678)\n",
            "Image: 000451.png, Size: (1020, 678)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /usr/local/lib/python3.10/dist-packages/basicsr/metrics/psnr_ssim.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSgJcnnwRq4R",
        "outputId": "e9ae05cf-ae2d-4201-bef9-1847095d385a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import cv2\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn.functional as F\n",
            "\n",
            "from basicsr.metrics.metric_util import reorder_image, to_y_channel\n",
            "from basicsr.utils.color_util import rgb2ycbcr_pt\n",
            "from basicsr.utils.registry import METRIC_REGISTRY\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_psnr(img, img2, crop_border, input_order='HWC', test_y_channel=False, **kwargs):\n",
            "    \"\"\"Calculate PSNR (Peak Signal-to-Noise Ratio).\n",
            "\n",
            "    Ref: https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n",
            "\n",
            "    Args:\n",
            "        img (ndarray): Images with range [0, 255].\n",
            "        img2 (ndarray): Images with range [0, 255].\n",
            "        crop_border (int): Cropped pixels in each edge of an image. These pixels are not involved in the calculation.\n",
            "        input_order (str): Whether the input order is 'HWC' or 'CHW'. Default: 'HWC'.\n",
            "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
            "\n",
            "    Returns:\n",
            "        float: PSNR result.\n",
            "    \"\"\"\n",
            "\n",
            "    assert img.shape == img2.shape, (f'Image shapes are different: {img.shape}, {img2.shape}.')\n",
            "    if input_order not in ['HWC', 'CHW']:\n",
            "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are \"HWC\" and \"CHW\"')\n",
            "    img = reorder_image(img, input_order=input_order)\n",
            "    img2 = reorder_image(img2, input_order=input_order)\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = to_y_channel(img)\n",
            "        img2 = to_y_channel(img2)\n",
            "\n",
            "    img = img.astype(np.float64)\n",
            "    img2 = img2.astype(np.float64)\n",
            "\n",
            "    mse = np.mean((img - img2)**2)\n",
            "    if mse == 0:\n",
            "        return float('inf')\n",
            "    return 10. * np.log10(255. * 255. / mse)\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_psnr_pt(img, img2, crop_border, test_y_channel=False, **kwargs):\n",
            "    \"\"\"Calculate PSNR (Peak Signal-to-Noise Ratio) (PyTorch version).\n",
            "\n",
            "    Ref: https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n",
            "\n",
            "    Args:\n",
            "        img (Tensor): Images with range [0, 1], shape (n, 3/1, h, w).\n",
            "        img2 (Tensor): Images with range [0, 1], shape (n, 3/1, h, w).\n",
            "        crop_border (int): Cropped pixels in each edge of an image. These pixels are not involved in the calculation.\n",
            "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
            "\n",
            "    Returns:\n",
            "        float: PSNR result.\n",
            "    \"\"\"\n",
            "\n",
            "    assert img.shape == img2.shape, (f'Image shapes are different: {img.shape}, {img2.shape}.')\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "        img2 = img2[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = rgb2ycbcr_pt(img, y_only=True)\n",
            "        img2 = rgb2ycbcr_pt(img2, y_only=True)\n",
            "\n",
            "    img = img.to(torch.float64)\n",
            "    img2 = img2.to(torch.float64)\n",
            "\n",
            "    mse = torch.mean((img - img2)**2, dim=[1, 2, 3])\n",
            "    return 10. * torch.log10(1. / (mse + 1e-8))\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_ssim(img, img2, crop_border, input_order='HWC', test_y_channel=False, **kwargs):\n",
            "    \"\"\"Calculate SSIM (structural similarity).\n",
            "\n",
            "    Ref:\n",
            "    Image quality assessment: From error visibility to structural similarity\n",
            "\n",
            "    The results are the same as that of the official released MATLAB code in\n",
            "    https://ece.uwaterloo.ca/~z70wang/research/ssim/.\n",
            "\n",
            "    For three-channel images, SSIM is calculated for each channel and then\n",
            "    averaged.\n",
            "\n",
            "    Args:\n",
            "        img (ndarray): Images with range [0, 255].\n",
            "        img2 (ndarray): Images with range [0, 255].\n",
            "        crop_border (int): Cropped pixels in each edge of an image. These pixels are not involved in the calculation.\n",
            "        input_order (str): Whether the input order is 'HWC' or 'CHW'.\n",
            "            Default: 'HWC'.\n",
            "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
            "\n",
            "    Returns:\n",
            "        float: SSIM result.\n",
            "    \"\"\"\n",
            "\n",
            "    assert img.shape == img2.shape, (f'Image shapes are different: {img.shape}, {img2.shape}.')\n",
            "    if input_order not in ['HWC', 'CHW']:\n",
            "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are \"HWC\" and \"CHW\"')\n",
            "    img = reorder_image(img, input_order=input_order)\n",
            "    img2 = reorder_image(img2, input_order=input_order)\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = to_y_channel(img)\n",
            "        img2 = to_y_channel(img2)\n",
            "\n",
            "    img = img.astype(np.float64)\n",
            "    img2 = img2.astype(np.float64)\n",
            "\n",
            "    ssims = []\n",
            "    for i in range(img.shape[2]):\n",
            "        ssims.append(_ssim(img[..., i], img2[..., i]))\n",
            "    return np.array(ssims).mean()\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_ssim_pt(img, img2, crop_border, test_y_channel=False, **kwargs):\n",
            "    \"\"\"Calculate SSIM (structural similarity) (PyTorch version).\n",
            "\n",
            "    Ref:\n",
            "    Image quality assessment: From error visibility to structural similarity\n",
            "\n",
            "    The results are the same as that of the official released MATLAB code in\n",
            "    https://ece.uwaterloo.ca/~z70wang/research/ssim/.\n",
            "\n",
            "    For three-channel images, SSIM is calculated for each channel and then\n",
            "    averaged.\n",
            "\n",
            "    Args:\n",
            "        img (Tensor): Images with range [0, 1], shape (n, 3/1, h, w).\n",
            "        img2 (Tensor): Images with range [0, 1], shape (n, 3/1, h, w).\n",
            "        crop_border (int): Cropped pixels in each edge of an image. These pixels are not involved in the calculation.\n",
            "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
            "\n",
            "    Returns:\n",
            "        float: SSIM result.\n",
            "    \"\"\"\n",
            "\n",
            "    assert img.shape == img2.shape, (f'Image shapes are different: {img.shape}, {img2.shape}.')\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "        img2 = img2[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = rgb2ycbcr_pt(img, y_only=True)\n",
            "        img2 = rgb2ycbcr_pt(img2, y_only=True)\n",
            "\n",
            "    img = img.to(torch.float64)\n",
            "    img2 = img2.to(torch.float64)\n",
            "\n",
            "    ssim = _ssim_pth(img * 255., img2 * 255.)\n",
            "    return ssim\n",
            "\n",
            "\n",
            "def _ssim(img, img2):\n",
            "    \"\"\"Calculate SSIM (structural similarity) for one channel images.\n",
            "\n",
            "    It is called by func:`calculate_ssim`.\n",
            "\n",
            "    Args:\n",
            "        img (ndarray): Images with range [0, 255] with order 'HWC'.\n",
            "        img2 (ndarray): Images with range [0, 255] with order 'HWC'.\n",
            "\n",
            "    Returns:\n",
            "        float: SSIM result.\n",
            "    \"\"\"\n",
            "\n",
            "    c1 = (0.01 * 255)**2\n",
            "    c2 = (0.03 * 255)**2\n",
            "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
            "    window = np.outer(kernel, kernel.transpose())\n",
            "\n",
            "    mu1 = cv2.filter2D(img, -1, window)[5:-5, 5:-5]  # valid mode for window size 11\n",
            "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
            "    mu1_sq = mu1**2\n",
            "    mu2_sq = mu2**2\n",
            "    mu1_mu2 = mu1 * mu2\n",
            "    sigma1_sq = cv2.filter2D(img**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
            "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
            "    sigma12 = cv2.filter2D(img * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
            "\n",
            "    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))\n",
            "    return ssim_map.mean()\n",
            "\n",
            "\n",
            "def _ssim_pth(img, img2):\n",
            "    \"\"\"Calculate SSIM (structural similarity) (PyTorch version).\n",
            "\n",
            "    It is called by func:`calculate_ssim_pt`.\n",
            "\n",
            "    Args:\n",
            "        img (Tensor): Images with range [0, 1], shape (n, 3/1, h, w).\n",
            "        img2 (Tensor): Images with range [0, 1], shape (n, 3/1, h, w).\n",
            "\n",
            "    Returns:\n",
            "        float: SSIM result.\n",
            "    \"\"\"\n",
            "    c1 = (0.01 * 255)**2\n",
            "    c2 = (0.03 * 255)**2\n",
            "\n",
            "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
            "    window = np.outer(kernel, kernel.transpose())\n",
            "    window = torch.from_numpy(window).view(1, 1, 11, 11).expand(img.size(1), 1, 11, 11).to(img.dtype).to(img.device)\n",
            "\n",
            "    mu1 = F.conv2d(img, window, stride=1, padding=0, groups=img.shape[1])  # valid mode\n",
            "    mu2 = F.conv2d(img2, window, stride=1, padding=0, groups=img2.shape[1])  # valid mode\n",
            "    mu1_sq = mu1.pow(2)\n",
            "    mu2_sq = mu2.pow(2)\n",
            "    mu1_mu2 = mu1 * mu2\n",
            "    sigma1_sq = F.conv2d(img * img, window, stride=1, padding=0, groups=img.shape[1]) - mu1_sq\n",
            "    sigma2_sq = F.conv2d(img2 * img2, window, stride=1, padding=0, groups=img.shape[1]) - mu2_sq\n",
            "    sigma12 = F.conv2d(img * img2, window, stride=1, padding=0, groups=img.shape[1]) - mu1_mu2\n",
            "\n",
            "    cs_map = (2 * sigma12 + c2) / (sigma1_sq + sigma2_sq + c2)\n",
            "    ssim_map = ((2 * mu1_mu2 + c1) / (mu1_sq + mu2_sq + c1)) * cs_map\n",
            "    return ssim_map.mean([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/usr/local/lib/python3.10/dist-packages/basicsr/metrics/psnr_ssim.py', 'r') as file:\n",
        "    file_content = file.read()"
      ],
      "metadata": {
        "id": "oV3AxtCx5DeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_content=\"\"\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from basicsr.metrics.metric_util import reorder_image, to_y_channel\n",
        "from basicsr.utils.color_util import rgb2ycbcr_pt\n",
        "from basicsr.utils.registry import METRIC_REGISTRY\n",
        "\n",
        "\n",
        "@METRIC_REGISTRY.register()\n",
        "def calculate_psnr(img, img2, crop_border, input_order='HWC', test_y_channel=False, **kwargs):\n",
        "\n",
        "    if img.shape != img2.shape:\n",
        "        # Resize the larger image to match the size of the smaller image\n",
        "        h, w = min(img.shape[0], img2.shape[0]), min(img.shape[1], img2.shape[1])\n",
        "        img = cv2.resize(img, (w, h))\n",
        "        img2 = cv2.resize(img2, (w, h))\n",
        "\n",
        "    assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
        "\n",
        "    if input_order not in ['HWC', 'CHW']:\n",
        "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are \"HWC\" and \"CHW\"')\n",
        "    img = reorder_image(img, input_order=input_order)\n",
        "    img2 = reorder_image(img2, input_order=input_order)\n",
        "\n",
        "    if crop_border != 0:\n",
        "        img = img[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
        "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
        "\n",
        "    if test_y_channel:\n",
        "        img = to_y_channel(img)\n",
        "        img2 = to_y_channel(img2)\n",
        "\n",
        "    img = img.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "\n",
        "    mse = np.mean((img - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 10. * np.log10(255. * 255. / mse)\n",
        "\n",
        "\n",
        "@METRIC_REGISTRY.register()\n",
        "def calculate_psnr_pt(img, img2, crop_border, test_y_channel=False, **kwargs):\n",
        "\n",
        "\n",
        "    if img.shape != img2.shape:\n",
        "        # Resize the larger image to match the size of the smaller image\n",
        "        h, w = min(img.shape[2], img2.shape[2]), min(img.shape[3], img2.shape[3])\n",
        "        img = F.interpolate(img, size=(h, w), mode='bilinear', align_corners=False)\n",
        "        img2 = F.interpolate(img2, size=(h, w), mode='bilinear', align_corners=False)\n",
        "\n",
        "        assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
        "\n",
        "    if crop_border != 0:\n",
        "        img = img[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
        "        img2 = img2[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
        "\n",
        "    if test_y_channel:\n",
        "        img = rgb2ycbcr_pt(img, y_only=True)\n",
        "        img2 = rgb2ycbcr_pt(img2, y_only=True)\n",
        "\n",
        "    img = img.to(torch.float64)\n",
        "    img2 = img2.to(torch.float64)\n",
        "\n",
        "    mse = torch.mean((img - img2)**2, dim=[1, 2, 3])\n",
        "    return 10. * torch.log10(1. / (mse + 1e-8))\n",
        "\n",
        "\n",
        "@METRIC_REGISTRY.register()\n",
        "def calculate_ssim(img, img2, crop_border, input_order='HWC', test_y_channel=False, **kwargs):\n",
        "\n",
        "\n",
        "\n",
        "    if img.shape != img2.shape:\n",
        "        # Resize the larger image to match the size of the smaller image\n",
        "        h, w = min(img.shape[0], img2.shape[0]), min(img.shape[1], img2.shape[1])\n",
        "        img = cv2.resize(img, (w, h))\n",
        "        img2 = cv2.resize(img2, (w, h))\n",
        "\n",
        "    assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
        "\n",
        "    if input_order not in ['HWC', 'CHW']:\n",
        "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are \"HWC\" and \"CHW\"')\n",
        "    img = reorder_image(img, input_order=input_order)\n",
        "    img2 = reorder_image(img2, input_order=input_order)\n",
        "\n",
        "    if crop_border != 0:\n",
        "        img = img[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
        "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
        "\n",
        "    if test_y_channel:\n",
        "        img = to_y_channel(img)\n",
        "        img2 = to_y_channel(img2)\n",
        "\n",
        "    img = img.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "\n",
        "    ssims = []\n",
        "    for i in range(img.shape[2]):\n",
        "        ssims.append(_ssim(img[..., i], img2[..., i]))\n",
        "    return np.array(ssims).mean()\n",
        "\n",
        "\n",
        "@METRIC_REGISTRY.register()\n",
        "def calculate_ssim_pt(img, img2, crop_border, test_y_channel=False, **kwargs):\n",
        "\n",
        "\n",
        "\n",
        "    if img.shape != img2.shape:\n",
        "        # Resize the larger image to match the size of the smaller image\n",
        "        h, w = min(img.shape[2], img2.shape[2]), min(img.shape[3], img2.shape[3])\n",
        "        img = F.interpolate(img, size=(h, w), mode='bilinear', align_corners=False)\n",
        "        img2 = F.interpolate(img2, size=(h, w), mode='bilinear', align_corners=False)\n",
        "\n",
        "        assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
        "\n",
        "    if crop_border != 0:\n",
        "        img = img[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
        "        img2 = img2[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
        "\n",
        "    if test_y_channel:\n",
        "        img = rgb2ycbcr_pt(img, y_only=True)\n",
        "        img2 = rgb2ycbcr_pt(img2, y_only=True)\n",
        "\n",
        "    img = img.to(torch.float64)\n",
        "    img2 = img2.to(torch.float64)\n",
        "\n",
        "    ssim = _ssim_pth(img * 255., img2 * 255.)\n",
        "    return ssim\n",
        "\n",
        "\n",
        "def _ssim(img, img2):\n",
        "\n",
        "\n",
        "    c1 = (0.01 * 255)**2\n",
        "    c2 = (0.03 * 255)**2\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img, -1, window)[5:-5, 5:-5]  # valid mode for window size 11\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "\n",
        "def _ssim_pth(img, img2):\n",
        "\n",
        "    c1 = (0.01 * 255)**2\n",
        "    c2 = (0.03 * 255)**2\n",
        "\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "    window = torch.from_numpy(window).view(1, 1, 11, 11).expand(img.size(1), 1, 11, 11).to(img.dtype).to(img.device)\n",
        "\n",
        "    mu1 = F.conv2d(img, window, stride=1, padding=0, groups=img.shape[1])  # valid mode\n",
        "    mu2 = F.conv2d(img2, window, stride=1, padding=0, groups=img2.shape[1])  # valid mode\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = F.conv2d(img * img, window, stride=1, padding=0, groups=img.shape[1]) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, stride=1, padding=0, groups=img.shape[1]) - mu2_sq\n",
        "    sigma12 = F.conv2d(img * img2, window, stride=1, padding=0, groups=img.shape[1]) - mu1_mu2\n",
        "\n",
        "    cs_map = (2 * sigma12 + c2) / (sigma1_sq + sigma2_sq + c2)\n",
        "    ssim_map = ((2 * mu1_mu2 + c1) / (mu1_sq + mu2_sq + c1)) * cs_map\n",
        "    return ssim_map.mean([1, 2, 3])\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VmbMHorZ5Dru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/usr/local/lib/python3.10/dist-packages/basicsr/metrics/psnr_ssim.py', 'w') as file:\n",
        "    file.write(file_content)\n"
      ],
      "metadata": {
        "id": "G2j0NHJB1gO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /usr/local/lib/python3.10/dist-packages/basicsr/metrics/psnr_ssim.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqtSXygi8JBF",
        "outputId": "d5a2f16e-e0d0-42ef-d2ac-44de329d5d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import cv2\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn.functional as F\n",
            "\n",
            "from basicsr.metrics.metric_util import reorder_image, to_y_channel\n",
            "from basicsr.utils.color_util import rgb2ycbcr_pt\n",
            "from basicsr.utils.registry import METRIC_REGISTRY\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_psnr(img, img2, crop_border, input_order='HWC', test_y_channel=False, **kwargs):\n",
            " \n",
            "    if img.shape != img2.shape:\n",
            "        # Resize the larger image to match the size of the smaller image\n",
            "        h, w = min(img.shape[0], img2.shape[0]), min(img.shape[1], img2.shape[1])\n",
            "        img = cv2.resize(img, (w, h))\n",
            "        img2 = cv2.resize(img2, (w, h))\n",
            "\n",
            "    assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
            "\n",
            "    if input_order not in ['HWC', 'CHW']:\n",
            "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are \"HWC\" and \"CHW\"')\n",
            "    img = reorder_image(img, input_order=input_order)\n",
            "    img2 = reorder_image(img2, input_order=input_order)\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = to_y_channel(img)\n",
            "        img2 = to_y_channel(img2)\n",
            "\n",
            "    img = img.astype(np.float64)\n",
            "    img2 = img2.astype(np.float64)\n",
            "\n",
            "    mse = np.mean((img - img2)**2)\n",
            "    if mse == 0:\n",
            "        return float('inf')\n",
            "    return 10. * np.log10(255. * 255. / mse)\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_psnr_pt(img, img2, crop_border, test_y_channel=False, **kwargs):\n",
            "\n",
            "\n",
            "    if img.shape != img2.shape:\n",
            "        # Resize the larger image to match the size of the smaller image\n",
            "        h, w = min(img.shape[2], img2.shape[2]), min(img.shape[3], img2.shape[3])\n",
            "        img = F.interpolate(img, size=(h, w), mode='bilinear', align_corners=False)\n",
            "        img2 = F.interpolate(img2, size=(h, w), mode='bilinear', align_corners=False)\n",
            "\n",
            "        assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "        img2 = img2[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = rgb2ycbcr_pt(img, y_only=True)\n",
            "        img2 = rgb2ycbcr_pt(img2, y_only=True)\n",
            "\n",
            "    img = img.to(torch.float64)\n",
            "    img2 = img2.to(torch.float64)\n",
            "\n",
            "    mse = torch.mean((img - img2)**2, dim=[1, 2, 3])\n",
            "    return 10. * torch.log10(1. / (mse + 1e-8))\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_ssim(img, img2, crop_border, input_order='HWC', test_y_channel=False, **kwargs):\n",
            "\n",
            "\n",
            "\n",
            "    if img.shape != img2.shape:\n",
            "        # Resize the larger image to match the size of the smaller image\n",
            "        h, w = min(img.shape[0], img2.shape[0]), min(img.shape[1], img2.shape[1])\n",
            "        img = cv2.resize(img, (w, h))\n",
            "        img2 = cv2.resize(img2, (w, h))\n",
            "\n",
            "    assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
            "\n",
            "    if input_order not in ['HWC', 'CHW']:\n",
            "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are \"HWC\" and \"CHW\"')\n",
            "    img = reorder_image(img, input_order=input_order)\n",
            "    img2 = reorder_image(img2, input_order=input_order)\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = to_y_channel(img)\n",
            "        img2 = to_y_channel(img2)\n",
            "\n",
            "    img = img.astype(np.float64)\n",
            "    img2 = img2.astype(np.float64)\n",
            "\n",
            "    ssims = []\n",
            "    for i in range(img.shape[2]):\n",
            "        ssims.append(_ssim(img[..., i], img2[..., i]))\n",
            "    return np.array(ssims).mean()\n",
            "\n",
            "\n",
            "@METRIC_REGISTRY.register()\n",
            "def calculate_ssim_pt(img, img2, crop_border, test_y_channel=False, **kwargs):\n",
            "  \n",
            "\n",
            "\n",
            "    if img.shape != img2.shape:\n",
            "        # Resize the larger image to match the size of the smaller image\n",
            "        h, w = min(img.shape[2], img2.shape[2]), min(img.shape[3], img2.shape[3])\n",
            "        img = F.interpolate(img, size=(h, w), mode='bilinear', align_corners=False)\n",
            "        img2 = F.interpolate(img2, size=(h, w), mode='bilinear', align_corners=False)\n",
            "\n",
            "        assert img.shape == img2.shape, (f'Image shapes are different after resizing: {img.shape}, {img2.shape}.')\n",
            "\n",
            "    if crop_border != 0:\n",
            "        img = img[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "        img2 = img2[:, :, crop_border:-crop_border, crop_border:-crop_border]\n",
            "\n",
            "    if test_y_channel:\n",
            "        img = rgb2ycbcr_pt(img, y_only=True)\n",
            "        img2 = rgb2ycbcr_pt(img2, y_only=True)\n",
            "\n",
            "    img = img.to(torch.float64)\n",
            "    img2 = img2.to(torch.float64)\n",
            "\n",
            "    ssim = _ssim_pth(img * 255., img2 * 255.)\n",
            "    return ssim\n",
            "\n",
            "\n",
            "def _ssim(img, img2):\n",
            "   \n",
            "\n",
            "    c1 = (0.01 * 255)**2\n",
            "    c2 = (0.03 * 255)**2\n",
            "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
            "    window = np.outer(kernel, kernel.transpose())\n",
            "\n",
            "    mu1 = cv2.filter2D(img, -1, window)[5:-5, 5:-5]  # valid mode for window size 11\n",
            "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
            "    mu1_sq = mu1**2\n",
            "    mu2_sq = mu2**2\n",
            "    mu1_mu2 = mu1 * mu2\n",
            "    sigma1_sq = cv2.filter2D(img**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
            "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
            "    sigma12 = cv2.filter2D(img * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
            "\n",
            "    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))\n",
            "    return ssim_map.mean()\n",
            "\n",
            "\n",
            "def _ssim_pth(img, img2):\n",
            "  \n",
            "    c1 = (0.01 * 255)**2\n",
            "    c2 = (0.03 * 255)**2\n",
            "\n",
            "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
            "    window = np.outer(kernel, kernel.transpose())\n",
            "    window = torch.from_numpy(window).view(1, 1, 11, 11).expand(img.size(1), 1, 11, 11).to(img.dtype).to(img.device)\n",
            "\n",
            "    mu1 = F.conv2d(img, window, stride=1, padding=0, groups=img.shape[1])  # valid mode\n",
            "    mu2 = F.conv2d(img2, window, stride=1, padding=0, groups=img2.shape[1])  # valid mode\n",
            "    mu1_sq = mu1.pow(2)\n",
            "    mu2_sq = mu2.pow(2)\n",
            "    mu1_mu2 = mu1 * mu2\n",
            "    sigma1_sq = F.conv2d(img * img, window, stride=1, padding=0, groups=img.shape[1]) - mu1_sq\n",
            "    sigma2_sq = F.conv2d(img2 * img2, window, stride=1, padding=0, groups=img.shape[1]) - mu2_sq\n",
            "    sigma12 = F.conv2d(img * img2, window, stride=1, padding=0, groups=img.shape[1]) - mu1_mu2\n",
            "\n",
            "    cs_map = (2 * sigma12 + c2) / (sigma1_sq + sigma2_sq + c2)\n",
            "    ssim_map = ((2 * mu1_mu2 + c1) / (mu1_sq + mu2_sq + c1)) * cs_map\n",
            "    return ssim_map.mean([1, 2, 3])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3  kdsrgan/test.py -opt options/test_kdsrgan_x4ST.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orJB6gJ6NvL",
        "outputId": "96795e54-8b70-4cb3-a073-464e23927e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "Disable distributed.\n",
            "Path already exists. Rename it to /content/gdrive/MyDrive/KDSR-GAN/results/test_KDSRGANx4STplus_400k_B12G4_archived_20240203_124247\n",
            "2024-02-03 12:42:47,296 INFO: \n",
            "                ____                _       _____  ____\n",
            "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
            "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
            "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
            "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
            "     ______                   __   __                 __      __\n",
            "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
            "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
            "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
            "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
            "    \n",
            "Version Information: \n",
            "\tBasicSR: 1.4.2\n",
            "\tPyTorch: 2.1.0+cu121\n",
            "\tTorchVision: 0.16.0+cu121\n",
            "2024-02-03 12:42:47,298 INFO: \n",
            "  name: test_KDSRGANx4STplus_400k_B12G4\n",
            "  model_type: KDSRGANSTModel\n",
            "  scale: 4\n",
            "  num_gpu: 1\n",
            "  manual_seed: 0\n",
            "  datasets:[\n",
            "    val:[\n",
            "      name: NTIRE2020-Track1\n",
            "      type: PairedImageDataset\n",
            "      dataroot_gt: /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized\n",
            "      dataroot_lq: /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized\n",
            "      io_backend:[\n",
            "        type: disk\n",
            "      ]\n",
            "      phase: val\n",
            "      scale: 4\n",
            "    ]\n",
            "  ]\n",
            "  network_g:[\n",
            "    type: BlindSR_ST\n",
            "    n_feats: 128\n",
            "    n_encoder_res: 6\n",
            "    scale: 4\n",
            "    n_sr_blocks: 42\n",
            "  ]\n",
            "  network_TA:[\n",
            "    type: BlindSR_TA\n",
            "    n_feats: 128\n",
            "    n_encoder_res: 6\n",
            "    scale: 4\n",
            "    n_sr_blocks: 42\n",
            "  ]\n",
            "  network_d:[\n",
            "    type: UNetDiscriminatorSN\n",
            "    num_in_ch: 3\n",
            "    num_feat: 64\n",
            "    skip_connection: True\n",
            "  ]\n",
            "  path:[\n",
            "    pretrain_network_TA: /content/gdrive/MyDrive/KDSR-GAN/experiments/debug_train_KDSRNetTAx4plus_1000k_B12G4/models/net_g_8.pth\n",
            "    pretrain_network_g: /content/gdrive/MyDrive/KDSR-GAN/experiments/train_KDSRGANx4STplus_400k_B12G4/models/net_d_latest.pth\n",
            "    param_key_g: params_ema\n",
            "    strict_load_g: False\n",
            "    ignore_resume_networks: network_TA\n",
            "    results_root: /content/gdrive/MyDrive/KDSR-GAN/results/test_KDSRGANx4STplus_400k_B12G4\n",
            "    log: /content/gdrive/MyDrive/KDSR-GAN/results/test_KDSRGANx4STplus_400k_B12G4\n",
            "    visualization: /content/gdrive/MyDrive/KDSR-GAN/results/test_KDSRGANx4STplus_400k_B12G4/visualization\n",
            "  ]\n",
            "  val:[\n",
            "    save_img: True\n",
            "    suffix: None\n",
            "    metrics:[\n",
            "      psnr:[\n",
            "        type: calculate_psnr\n",
            "        crop_border: 4\n",
            "        test_y_channel: True\n",
            "      ]\n",
            "    ]\n",
            "  ]\n",
            "  dist: False\n",
            "  rank: 0\n",
            "  world_size: 1\n",
            "  auto_resume: False\n",
            "  is_train: False\n",
            "\n",
            "2024-02-03 12:42:47,303 INFO: Dataset [PairedImageDataset] - NTIRE2020-Track1 is built.\n",
            "2024-02-03 12:42:47,304 INFO: Number of test images in NTIRE2020-Track1: 52\n",
            "2024-02-03 12:42:47,534 INFO: Network [BlindSR_ST] is created.\n",
            "2024-02-03 12:42:47,893 INFO: Network: BlindSR_ST, with parameters: 18,846,107\n",
            "2024-02-03 12:42:47,893 INFO: BlindSR_ST(\n",
            "  (G): KDSR(\n",
            "    (sub_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (add_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (head): Sequential(\n",
            "      (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (body): Sequential(\n",
            "      (0): DAG(\n",
            "        (body): Sequential(\n",
            "          (0): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (1): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (2): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (3): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (4): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (5): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (6): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (7): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (8): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (9): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (10): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (11): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (12): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (13): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (14): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (15): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (16): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (17): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (18): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (19): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (20): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (21): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (22): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (23): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (24): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (25): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (26): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (27): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (28): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (29): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (30): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (31): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (32): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (33): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (34): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (35): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (36): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (37): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (38): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (39): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (40): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "          (41): IDR_DCRB(\n",
            "            (da_conv1): IDR_DDC(\n",
            "              (kernel): Sequential(\n",
            "                (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "                (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "                (2): Linear(in_features=128, out_features=1152, bias=False)\n",
            "              )\n",
            "            )\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (tail): Sequential(\n",
            "      (0): Upsampler(\n",
            "        (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): PixelShuffle(upscale_factor=2)\n",
            "        (2): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): PixelShuffle(upscale_factor=2)\n",
            "      )\n",
            "      (1): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (E_st): KD_IDE(\n",
            "    (E): Sequential(\n",
            "      (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (2): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (9): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (14): AdaptiveAvgPool2d(output_size=1)\n",
            "    )\n",
            "    (mlp): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "    )\n",
            "    (compress): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
            "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (pixel_unshuffle): PixelUnshuffle(downscale_factor=4)\n",
            ")\n",
            "2024-02-03 12:42:49,700 INFO: Loading: params_ema does not exist, use params.\n",
            "2024-02-03 12:42:49,700 INFO: Loading BlindSR_ST model from /content/gdrive/MyDrive/KDSR-GAN/experiments/train_KDSRGANx4STplus_400k_B12G4/models/net_d_latest.pth, with param key: [params].\n",
            "2024-02-03 12:42:49,715 WARNING: Current net - loaded net:\n",
            "2024-02-03 12:42:49,716 WARNING:   E_st.E.0.bias\n",
            "2024-02-03 12:42:49,716 WARNING:   E_st.E.0.weight\n",
            "2024-02-03 12:42:49,716 WARNING:   E_st.E.10.bias\n",
            "2024-02-03 12:42:49,716 WARNING:   E_st.E.10.weight\n",
            "2024-02-03 12:42:49,716 WARNING:   E_st.E.12.bias\n",
            "2024-02-03 12:42:49,716 WARNING:   E_st.E.12.weight\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.2.body.0.bias\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.2.body.0.weight\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.2.body.2.bias\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.2.body.2.weight\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.3.body.0.bias\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.3.body.0.weight\n",
            "2024-02-03 12:42:49,717 WARNING:   E_st.E.3.body.2.bias\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.3.body.2.weight\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.4.body.0.bias\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.4.body.0.weight\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.4.body.2.bias\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.4.body.2.weight\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.5.body.0.bias\n",
            "2024-02-03 12:42:49,718 WARNING:   E_st.E.5.body.0.weight\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.5.body.2.bias\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.5.body.2.weight\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.6.body.0.bias\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.6.body.0.weight\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.6.body.2.bias\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.6.body.2.weight\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.7.body.0.bias\n",
            "2024-02-03 12:42:49,719 WARNING:   E_st.E.7.body.0.weight\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.E.7.body.2.bias\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.E.7.body.2.weight\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.E.8.bias\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.E.8.weight\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.compress.0.bias\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.compress.0.weight\n",
            "2024-02-03 12:42:49,720 WARNING:   E_st.mlp.0.bias\n",
            "2024-02-03 12:42:49,721 WARNING:   E_st.mlp.0.weight\n",
            "2024-02-03 12:42:49,721 WARNING:   E_st.mlp.2.bias\n",
            "2024-02-03 12:42:49,721 WARNING:   E_st.mlp.2.weight\n",
            "2024-02-03 12:42:49,721 WARNING:   G.add_mean.bias\n",
            "2024-02-03 12:42:49,721 WARNING:   G.add_mean.weight\n",
            "2024-02-03 12:42:49,721 WARNING:   G.body.0.body.0.conv1.bias\n",
            "2024-02-03 12:42:49,721 WARNING:   G.body.0.body.0.conv1.weight\n",
            "2024-02-03 12:42:49,721 WARNING:   G.body.0.body.0.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.0.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.1.conv1.bias\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.1.conv1.weight\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.1.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.1.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.10.conv1.bias\n",
            "2024-02-03 12:42:49,722 WARNING:   G.body.0.body.10.conv1.weight\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.10.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.10.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.11.conv1.bias\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.11.conv1.weight\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.11.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.11.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.12.conv1.bias\n",
            "2024-02-03 12:42:49,723 WARNING:   G.body.0.body.12.conv1.weight\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.12.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.12.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.13.conv1.bias\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.13.conv1.weight\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.13.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.13.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,724 WARNING:   G.body.0.body.14.conv1.bias\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.14.conv1.weight\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.14.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.14.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.15.conv1.bias\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.15.conv1.weight\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.15.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,725 WARNING:   G.body.0.body.15.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.16.conv1.bias\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.16.conv1.weight\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.16.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.16.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.17.conv1.bias\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.17.conv1.weight\n",
            "2024-02-03 12:42:49,726 WARNING:   G.body.0.body.17.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.17.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.18.conv1.bias\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.18.conv1.weight\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.18.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.18.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.19.conv1.bias\n",
            "2024-02-03 12:42:49,727 WARNING:   G.body.0.body.19.conv1.weight\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.19.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.19.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.2.conv1.bias\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.2.conv1.weight\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.2.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.2.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.20.conv1.bias\n",
            "2024-02-03 12:42:49,728 WARNING:   G.body.0.body.20.conv1.weight\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.20.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.20.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.21.conv1.bias\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.21.conv1.weight\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.21.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.21.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,729 WARNING:   G.body.0.body.22.conv1.bias\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.22.conv1.weight\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.22.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.22.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.23.conv1.bias\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.23.conv1.weight\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.23.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,730 WARNING:   G.body.0.body.23.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,731 WARNING:   G.body.0.body.24.conv1.bias\n",
            "2024-02-03 12:42:49,731 WARNING:   G.body.0.body.24.conv1.weight\n",
            "2024-02-03 12:42:49,731 WARNING:   G.body.0.body.24.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,731 WARNING:   G.body.0.body.24.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,731 WARNING:   G.body.0.body.25.conv1.bias\n",
            "2024-02-03 12:42:49,731 WARNING:   G.body.0.body.25.conv1.weight\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.25.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.25.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.26.conv1.bias\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.26.conv1.weight\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.26.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.26.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.27.conv1.bias\n",
            "2024-02-03 12:42:49,732 WARNING:   G.body.0.body.27.conv1.weight\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.27.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.27.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.28.conv1.bias\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.28.conv1.weight\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.28.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.28.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,733 WARNING:   G.body.0.body.29.conv1.bias\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.29.conv1.weight\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.29.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.29.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.3.conv1.bias\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.3.conv1.weight\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.3.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,734 WARNING:   G.body.0.body.3.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.30.conv1.bias\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.30.conv1.weight\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.30.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.30.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.31.conv1.bias\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.31.conv1.weight\n",
            "2024-02-03 12:42:49,735 WARNING:   G.body.0.body.31.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.31.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.32.conv1.bias\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.32.conv1.weight\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.32.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.32.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.33.conv1.bias\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.33.conv1.weight\n",
            "2024-02-03 12:42:49,736 WARNING:   G.body.0.body.33.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.33.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.34.conv1.bias\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.34.conv1.weight\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.34.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.34.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.35.conv1.bias\n",
            "2024-02-03 12:42:49,737 WARNING:   G.body.0.body.35.conv1.weight\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.35.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.35.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.36.conv1.bias\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.36.conv1.weight\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.36.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.36.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.37.conv1.bias\n",
            "2024-02-03 12:42:49,738 WARNING:   G.body.0.body.37.conv1.weight\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.37.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.37.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.38.conv1.bias\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.38.conv1.weight\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.38.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.38.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,739 WARNING:   G.body.0.body.39.conv1.bias\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.39.conv1.weight\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.39.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.39.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.4.conv1.bias\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.4.conv1.weight\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.4.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,740 WARNING:   G.body.0.body.4.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.40.conv1.bias\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.40.conv1.weight\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.40.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.40.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.41.conv1.bias\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.41.conv1.weight\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.41.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,741 WARNING:   G.body.0.body.41.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.5.conv1.bias\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.5.conv1.weight\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.5.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.5.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.6.conv1.bias\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.6.conv1.weight\n",
            "2024-02-03 12:42:49,742 WARNING:   G.body.0.body.6.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.6.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.7.conv1.bias\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.7.conv1.weight\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.7.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.7.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.8.conv1.bias\n",
            "2024-02-03 12:42:49,743 WARNING:   G.body.0.body.8.conv1.weight\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.0.body.8.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.0.body.8.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.0.body.9.conv1.bias\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.0.body.9.conv1.weight\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.0.body.9.da_conv1.kernel.0.weight\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.0.body.9.da_conv1.kernel.2.weight\n",
            "2024-02-03 12:42:49,744 WARNING:   G.body.1.bias\n",
            "2024-02-03 12:42:49,745 WARNING:   G.body.1.weight\n",
            "2024-02-03 12:42:49,745 WARNING:   G.head.0.bias\n",
            "2024-02-03 12:42:49,745 WARNING:   G.head.0.weight\n",
            "2024-02-03 12:42:49,745 WARNING:   G.sub_mean.bias\n",
            "2024-02-03 12:42:49,745 WARNING:   G.sub_mean.weight\n",
            "2024-02-03 12:42:49,745 WARNING:   G.tail.0.0.bias\n",
            "2024-02-03 12:42:49,745 WARNING:   G.tail.0.0.weight\n",
            "2024-02-03 12:42:49,745 WARNING:   G.tail.0.2.bias\n",
            "2024-02-03 12:42:49,746 WARNING:   G.tail.0.2.weight\n",
            "2024-02-03 12:42:49,746 WARNING:   G.tail.1.bias\n",
            "2024-02-03 12:42:49,746 WARNING:   G.tail.1.weight\n",
            "2024-02-03 12:42:49,746 WARNING: Loaded net - current net:\n",
            "2024-02-03 12:42:49,746 WARNING:   conv0.bias\n",
            "2024-02-03 12:42:49,746 WARNING:   conv0.weight\n",
            "2024-02-03 12:42:49,746 WARNING:   conv1.weight_orig\n",
            "2024-02-03 12:42:49,747 WARNING:   conv1.weight_u\n",
            "2024-02-03 12:42:49,747 WARNING:   conv1.weight_v\n",
            "2024-02-03 12:42:49,747 WARNING:   conv2.weight_orig\n",
            "2024-02-03 12:42:49,747 WARNING:   conv2.weight_u\n",
            "2024-02-03 12:42:49,747 WARNING:   conv2.weight_v\n",
            "2024-02-03 12:42:49,747 WARNING:   conv3.weight_orig\n",
            "2024-02-03 12:42:49,747 WARNING:   conv3.weight_u\n",
            "2024-02-03 12:42:49,747 WARNING:   conv3.weight_v\n",
            "2024-02-03 12:42:49,748 WARNING:   conv4.weight_orig\n",
            "2024-02-03 12:42:49,748 WARNING:   conv4.weight_u\n",
            "2024-02-03 12:42:49,748 WARNING:   conv4.weight_v\n",
            "2024-02-03 12:42:49,748 WARNING:   conv5.weight_orig\n",
            "2024-02-03 12:42:49,748 WARNING:   conv5.weight_u\n",
            "2024-02-03 12:42:49,748 WARNING:   conv5.weight_v\n",
            "2024-02-03 12:42:49,748 WARNING:   conv6.weight_orig\n",
            "2024-02-03 12:42:49,749 WARNING:   conv6.weight_u\n",
            "2024-02-03 12:42:49,749 WARNING:   conv6.weight_v\n",
            "2024-02-03 12:42:49,749 WARNING:   conv7.weight_orig\n",
            "2024-02-03 12:42:49,749 WARNING:   conv7.weight_u\n",
            "2024-02-03 12:42:49,749 WARNING:   conv7.weight_v\n",
            "2024-02-03 12:42:49,749 WARNING:   conv8.weight_orig\n",
            "2024-02-03 12:42:49,750 WARNING:   conv8.weight_u\n",
            "2024-02-03 12:42:49,750 WARNING:   conv8.weight_v\n",
            "2024-02-03 12:42:49,750 WARNING:   conv9.bias\n",
            "2024-02-03 12:42:49,750 WARNING:   conv9.weight\n",
            "2024-02-03 12:42:49,970 INFO: Network [BlindSR_TA] is created.\n",
            "2024-02-03 12:42:56,980 INFO: Loading BlindSR_TA model from /content/gdrive/MyDrive/KDSR-GAN/experiments/debug_train_KDSRNetTAx4plus_1000k_B12G4/models/net_g_8.pth, with param key: [params_ema].\n",
            "2024-02-03 12:42:57,134 INFO: Model [KDSRGANSTModel] is created.\n",
            "2024-02-03 12:42:57,135 INFO: Testing NTIRE2020-Track1...\n",
            "2024-02-03 12:48:54,234 INFO: Validation NTIRE2020-Track1\n",
            "\t # psnr: 13.8368\tBest: 13.8368 @ test_KDSRGANx4STplus_400k_B12G4 iter\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lpips\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYfuckl_Bieg",
        "outputId": "1697e59f-8c21-4351-de03-d2b17c77f179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.2.1->lpips) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.2.1->lpips) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.2.1->lpips) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.2.1->lpips) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n",
            "Installing collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exi_ywQBBiud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3  Metric/PSNR.py --folder_gt /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized  --folder_restored /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS3X3Meg6UuO",
        "outputId": "0c10700f-e08a-4080-ab59-2c4f50b6ff7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "Average: PSNR: 44.885391\n",
            "Average: SSIM: 0.991477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!python3  Metric/LPIPS.py --folder_gt /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_gt_resized  --folder_restored /content/gdrive/MyDrive/KDSR-GAN/datasets/test/DF2K_lq_resized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw4fTCBoBXro",
        "outputId": "5e05df22-81dd-4f4b-bf71-5e7c73427acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\",\n",
              " '  warnings.warn(',\n",
              " 'Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]',\n",
              " \"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\",\n",
              " '  warnings.warn(',\n",
              " \"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\",\n",
              " '  warnings.warn(msg)',\n",
              " 'Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth',\n",
              " '',\n",
              " '  0% 0.00/528M [00:00<?, ?B/s]',\n",
              " '  2% 8.62M/528M [00:00<00:06, 90.4MB/s]',\n",
              " '  4% 22.1M/528M [00:00<00:04, 121MB/s] ',\n",
              " '  7% 39.5M/528M [00:00<00:03, 149MB/s]',\n",
              " ' 11% 56.9M/528M [00:00<00:03, 162MB/s]',\n",
              " ' 14% 75.3M/528M [00:00<00:02, 173MB/s]',\n",
              " ' 18% 93.2M/528M [00:00<00:02, 178MB/s]',\n",
              " ' 21% 110M/528M [00:00<00:02, 165MB/s] ',\n",
              " ' 24% 126M/528M [00:00<00:02, 145MB/s]',\n",
              " ' 27% 142M/528M [00:00<00:02, 152MB/s]',\n",
              " ' 30% 159M/528M [00:01<00:02, 157MB/s]',\n",
              " ' 33% 174M/528M [00:01<00:02, 156MB/s]',\n",
              " ' 36% 189M/528M [00:01<00:02, 156MB/s]',\n",
              " ' 39% 204M/528M [00:01<00:02, 155MB/s]',\n",
              " ' 42% 221M/528M [00:01<00:01, 162MB/s]',\n",
              " ' 45% 238M/528M [00:01<00:01, 166MB/s]',\n",
              " ' 48% 254M/528M [00:01<00:01, 165MB/s]',\n",
              " ' 51% 271M/528M [00:01<00:01, 168MB/s]',\n",
              " ' 55% 288M/528M [00:01<00:01, 171MB/s]',\n",
              " ' 58% 304M/528M [00:02<00:01, 148MB/s]',\n",
              " ' 60% 319M/528M [00:02<00:01, 121MB/s]',\n",
              " ' 63% 331M/528M [00:02<00:01, 115MB/s]',\n",
              " ' 65% 343M/528M [00:02<00:01, 111MB/s]',\n",
              " ' 67% 354M/528M [00:02<00:01, 110MB/s]',\n",
              " ' 69% 365M/528M [00:02<00:01, 105MB/s]',\n",
              " ' 71% 375M/528M [00:02<00:01, 106MB/s]',\n",
              " ' 73% 385M/528M [00:02<00:01, 105MB/s]',\n",
              " ' 75% 396M/528M [00:03<00:01, 106MB/s]',\n",
              " ' 77% 406M/528M [00:03<00:01, 106MB/s]',\n",
              " ' 79% 416M/528M [00:03<00:01, 107MB/s]',\n",
              " ' 81% 429M/528M [00:03<00:00, 113MB/s]',\n",
              " ' 83% 440M/528M [00:03<00:00, 116MB/s]',\n",
              " ' 86% 452M/528M [00:03<00:00, 118MB/s]',\n",
              " ' 88% 464M/528M [00:03<00:00, 119MB/s]',\n",
              " ' 90% 475M/528M [00:03<00:00, 120MB/s]',\n",
              " ' 92% 487M/528M [00:03<00:00, 112MB/s]',\n",
              " ' 94% 498M/528M [00:03<00:00, 111MB/s]',\n",
              " ' 96% 508M/528M [00:04<00:00, 108MB/s]',\n",
              " ' 98% 519M/528M [00:04<00:00, 105MB/s]',\n",
              " '100% 528M/528M [00:04<00:00, 130MB/s]',\n",
              " 'Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/vgg.pth',\n",
              " 'Average: LPIPS: 0.018536']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xtK-7sKEzjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}